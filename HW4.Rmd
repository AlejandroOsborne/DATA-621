---
title: "Homework 4"
author: "Alejandro D. Osborne"
date: "December 2, 2018"
output:
  html_document: default
  pdf_document: default
---

```{r}
library(tidyverse) 
library(knitr)
library(psych)
library(faraway)
library(kableExtra)
library(ggiraph)
library(cowplot)
library(reshape2)
library(corrgram)
library(gridExtra)
library(usdm)
library(mice)
library(pROC)
library(reshape2)
library(caTools)
library(ROCR)
library(stargazer)
library(data.table)
library(car)
library(MASS)
library(ISLR)
library(leaps)
library(fBasics)
library(GGally)
library(Amelia)
library(ggplot2)
library(caret)
library(DataExplorer)
library(dplyr)
```

```{r}
train <- read.csv("https://raw.githubusercontent.com/AlejandroOsborne/DATA-621/master/insurance_training_data.csv")
test <- read.csv("https://raw.githubusercontent.com/AlejandroOsborne/DATA-621/master/insurance-evaluation-data.csv")
```

```{r}
train$INDEX <- NULL
test$INDEX <- NULL
test$TARGET_AMT <- NULL
test$TARGET_FLAG <- NULL
train$TARGET_FLAG <- as.factor(train$TARGET_FLAG)
```

1. DATA EXPLORATION


```{r}
cleanMoney <- function(vector) {
    i <- gsub(",", "", vector)
    i <- as.numeric(gsub("[\\$,]", "", i))
    return(i)
}
train$INCOME <- cleanMoney(train$INCOME)
train$HOME_VAL <- cleanMoney(train$HOME_VAL)
train$BLUEBOOK <- cleanMoney(train$BLUEBOOK)
train$OLDCLAIM <- cleanMoney(train$OLDCLAIM)
test$INCOME <- cleanMoney(test$INCOME)
test$HOME_VAL <- cleanMoney(test$HOME_VAL)
test$BLUEBOOK <- cleanMoney(test$BLUEBOOK)
test$OLDCLAIM <- cleanMoney(test$OLDCLAIM)
```




```{r, echo=FALSE, warning=FALSE}
summary <- describe(train[,c(1:25)])[,c(2:5,8,9,11,12)]
knitr::kable(summary)
```

```{r, echo=FALSE, warning=FALSE}
knitr::kable(table(train$TARGET_FLAG))
sum(train$TARGET_AMT ==0)
```

#Histogram
```{r, echo=FALSE, warning=FALSE}
out <- split_columns(train)
plot_histogram(out$continuous)
plot_bar(out$discrete)
```

#Relationship of Predict

```{r, echo=FALSE, warning=FALSE}
plot_scatterplot(train[2:25,], "TARGET_AMT", "jitter")
```

2. DATA PREPARATION



```{r}
train$HOMEKIDS[train$HOMEKIDS != 0 ] <- 1
test$HOMEKIDS[test$HOMEKIDS != 0 ] <- 1
train$CAR_AGE[train$CAR_AGE < 0 ] <- 0
test$CAR_AGE[test$CAR_AGE < 0 ] <- 0
train$JOB <- as.character(train$JOB)
train$JOB[train$JOB == ""] <- "Unknown"
train$JOB <- as.factor(train$JOB)
test$JOB <- as.character(test$JOB)
test$JOB[test$JOB == ""] <- "Unknown"
test$JOB <- as.factor(test$JOB)
train$EDUCATION <- ifelse(train$EDUCATION %in% c("PhD", "Masters"), 0, 1)
```


```{r}
plot_missing(train)
```

```{r}
mice_imputes <- mice(train, m = 2, maxit = 2, print = FALSE)
densityplot(mice_imputes)
```

```{r}
m <- median(train$AGE, na.rm = T)
train$AGE[is.na(train$AGE)] <- m
mice_train <-  mice(train, m = 1, maxit = 1, print = FALSE)
train <- complete(mice_train)
mice_test <- mice(test, m = 1, maxit = 1, print = FALSE)
test <- complete(mice_test)
```

3. BUILD MODELS


```{r, echo=FALSE, warning=FALSE}
set.seed(121)
train_logistic <- train
train_logistic$TARGET_AMT <- NULL
split <- createDataPartition(train_logistic$TARGET_FLAG, p=0.85, list=FALSE)
partial_train <- train_logistic[split, ]
validation <- train_logistic[ -split, ]
mod1 <- train(TARGET_FLAG ~., data = partial_train, 
              method = "glm", family = "binomial",
              trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
              tuneLength = 5,
              preProcess = c("center", "scale"))
knitr::kable(vif(mod1$finalModel))
```

```{r, echo=FALSE, warning=FALSE}
# remove low p-values
mod2 <- train(TARGET_FLAG ~ KIDSDRIV + INCOME + PARENT1 + HOME_VAL +
                  MSTATUS + JOB + TRAVTIME + CAR_USE + BLUEBOOK + TIF + 
                  CAR_TYPE + OLDCLAIM + CLM_FREQ + REVOKED + 
                  MVR_PTS + URBANICITY, 
            data = partial_train, 
            method = "glm", family = "binomial",
            trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
            tuneLength = 5, 
            preProcess = c("center", "scale"))
knitr::kable(vif(mod2$finalModel))
```

```{r, echo=FALSE, warning=FALSE}
## Reduce Collinearity by removing high VIFs
mod3 <- train(TARGET_FLAG ~ KIDSDRIV + AGE + HOMEKIDS + YOJ + 
                  PARENT1 + HOME_VAL + MSTATUS + JOB + 
                  TRAVTIME + CAR_USE + BLUEBOOK + TIF + CAR_TYPE + 
                  RED_CAR + OLDCLAIM + CLM_FREQ + REVOKED + MVR_PTS + 
                  CAR_AGE + URBANICITY, 
              data = partial_train, 
              method = "glm", family = "binomial",
              trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
              tuneLength = 5, 
              preProcess = c("center", "scale"))
knitr::kable(vif(mod3$finalModel))
```


```{r, echo=FALSE, warning=FALSE}
## reduce collinearity, and remove low values
mod4 <- train(TARGET_FLAG ~ KIDSDRIV + 
                  PARENT1 + HOME_VAL + MSTATUS + JOB + 
                  TRAVTIME + CAR_USE + BLUEBOOK + TIF + CAR_TYPE + 
                  OLDCLAIM + CLM_FREQ + REVOKED + MVR_PTS + 
                  CAR_AGE + URBANICITY, 
            data = partial_train, 
            method = "glm", family = "binomial",
            trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
            tuneLength = 5, 
            preProcess = c("center", "scale"))
knitr::kable(vif(mod4$finalModel))
```


```{r}
set.seed(121)
train_regression <- train
train_regression <- train_regression[train_regression$TARGET_FLAG == 1, ]
train_regression$TARGET_FLAG <- NULL
mod1lm <- train(TARGET_AMT ~., data = train_regression, 
              method = "lm", 
              trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
              tuneLength = 5, 
              preProcess = c("center", "scale"))
```

```{r}
mod2lm <- train(TARGET_AMT ~ HOME_VAL +  
                  CAR_USE + BLUEBOOK + TIF + CAR_TYPE + 
                  OLDCLAIM + CLM_FREQ + REVOKED + MVR_PTS + 
                  CAR_AGE + URBANICITY, data = train_regression, 
              method = "lm", 
              trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
              tuneLength = 5, 
              preProcess = c("center", "scale"))
```



```{r}
mod3lm <- train(TARGET_AMT ~ BLUEBOOK + REVOKED + MVR_PTS + 
                  CAR_AGE, data = train_regression, 
              method = "lm", 
              trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
              tuneLength = 5, 
              preProcess = c("center", "scale"))
```


```{r, echo=FALSE, warning=FALSE}
preds1 <- predict(mod1, newdata = validation)
preds2 <- predict(mod2, newdata = validation)
preds3 <- predict(mod3, newdata = validation)
preds4 <- predict(mod4, newdata = validation)
m1cM <- confusionMatrix(preds1, validation$TARGET_FLAG, 
                        mode = "everything")
m2cM <- confusionMatrix(preds2, validation$TARGET_FLAG, 
                        mode = "everything")
m3cM <- confusionMatrix(preds3, validation$TARGET_FLAG, 
                        mode = "everything")
m4cM <- confusionMatrix(preds4, validation$TARGET_FLAG, 
                        mode = "everything")
par(mfrow=c(2,2))
fourfoldplot(m1cM$table, color = c("#B22222", "#2E8B57"), main="Mod1")
fourfoldplot(m2cM$table, color = c("#B22222", "#2E8B57"), main="Mod2")
fourfoldplot(m3cM$table, color = c("#B22222", "#2E8B57"), main="Mod3")
fourfoldplot(m4cM$table, color = c("#B22222", "#2E8B57"), main="Mod4")
```


```{r, echo=FALSE, warning=FALSE}
eval <- data.frame(m1cM$byClass, 
                   m2cM$byClass, 
                   m3cM$byClass, 
                   m4cM$byClass)
eval <- data.frame(t(eval))
# manipulate results DF
eval <- dplyr::select(eval, Sensitivity, Specificity, Precision, Recall, F1)
row.names(eval) <- c("Model1", "Model2", "Model3", "Model4")
knitr::kable(eval)
```


```{r, echo=FALSE, warning=FALSE}
getROC <- function(model) {
    name <- deparse(substitute(model))
    pred.prob1 <- predict(model, newdata = train, type="prob")
    p1 <- data.frame(pred = train$TARGET_FLAG, prob = pred.prob1[[1]])
    p1 <- p1[order(p1$prob),]
    rocobj <- roc(p1$pred, p1$prob)
    plot(rocobj, asp=NA, legacy.axes = TRUE, print.auc=TRUE,
         xlab="Specificity", main = name)
}
par(mfrow=c(2,2))
getROC(mod1)
getROC(mod2)
getROC(mod3)
getROC(mod4)
```


```{r, echo=FALSE, warning=FALSE}
finalmod <- train(TARGET_FLAG ~ KIDSDRIV + 
                  PARENT1 + HOME_VAL + MSTATUS + JOB + 
                  TRAVTIME + CAR_USE + BLUEBOOK + TIF + CAR_TYPE + 
                  OLDCLAIM + CLM_FREQ + REVOKED + MVR_PTS + 
                  CAR_AGE + URBANICITY, 
            data = train, 
            method = "glm", family = "binomial",
            trControl = trainControl(
                  method = "cv", number = 10,
                  savePredictions = TRUE),
            tuneLength = 5, 
            preProcess = c("center", "scale"))
summary(finalmod)
plot(finalmod$finalModel)
```


```{r}
df <- data.frame()
df <- rbind(df, mod1lm$results)
df <- rbind(df, mod2lm$results)
df <- rbind(df, mod3lm$results)
df$intercept <- c("Mod1", "Mod2", "Mod3")
colnames(df)[1] <- "model"
knitr::kable(df)
```


```{r, warning=FALSE, message=FALSE}
finalpreds <- predict(finalmod, test)
finalpreds.probs <- predict(finalmod, test, type="prob")
finaldf <- cbind(finalpreds.probs, TARGET_FLAG=finalpreds)
finalAmountPreds <- predict(mod3lm, test)
finaldf <- cbind(finaldf, TARGET_AMT = finalAmountPreds)
write.csv(finaldf, 'Assignment4Predict.csv', row.names = FALSE)
```
